# SkillFactory DataScience
 
## Module_5: Разведывательный анализ данных (Exploratory data analysis) + Feature Engineering (FE) + ML и предсказательная классификация  

## Цель: Научиться подготавливать данные и модель, включая гиперпараметры, для решения задачи кредитного скоринга (классификации)

## Задачи: 
* Анализируя результат ML попытаться обогатить модель подходящими параметрам
* Попробовать разные методы разбиения данных
* Посмотреть влияние гиперпараметров
* Посмотреть взаимосвязь различных метрик (f1, auc и другие)


# Результат и выводы


## Кратка информацию о данных
* Дана некототорая некоторая кредитная история и сопутствующая информация банков. 
* Нужно предсказать дефолтных клиентов.
* В качестве скоринга необходимо улучшить roc auc. 

## Резултаты (что было проделано)
1. В данных нет пропусков практически, только в категории образование. Тестирование показало, что лучше всего пропуски заменить на SCH, чем добавлять новую категорию (без обр). 
2. Данные по дате регистрации заявки на получение кредита были переведены в численные значения (в единицах "день"). 
3. Все численные параметры были до полинома 2й степени перемножены и добавлены в рассмотрение.  
4. Были попытки добавления полиномов более высокого порядка, но значительных преимуществ это не принесло.
5. Все численные переменные были логорифмированы, что сделало их распределение более нормальным и улучшело предсказание.
6. В некоторых данных есть выбросы (например, очень высокие доходы), но с ними решено было ничего не делать. 
7. Сравнивал оптимизацию гиперпараметров (2 массива гиперпараметров сравнивались отдельно) оптимизирую f1 и roc_auc. f1 дает более высокую прибыль (см. далее), а roc_auc повышает скоринг (этот параметр сравнивается в лидерборде).
8. roc_auc, confusion_matrix и public leader board scoring, а также короткое описание изменений написаны в df=results в конце документа. Там видно, что если гиперпараметры не оптимизировать, или оптимизировать для roc_auc, то f1 будет низким, также как и предполагаемая выручка компании. Это происходит из-за большого колличества ложно-отрицательных предсказаний (выдача заведомо дефолтных-кредитов).
9. Вывод, roc_auc хороший параметр, но f1 лучше отображает потребности компании, а лучше ввести функцию типа profit.
10. Пробовал разные типы разбиения данных: train_test_split, KFold, StratifiedShuffleSplit, они все показывали похожие на train_test_split метрики. StratifiedShuffleSplit на несколько тысячных улучшить модель. Однако, стандартное отклонение полученное KFold разбиением было около 0.01. Хотя это не так много, но именно на столько отличается мой результат от первого места. 
11. Лучший результат на Kaggle LeaderBoard от 20210203, 9 место Andrey Pravdivtsev скоринг 0.73850


## Что еще можно было бы сделать?
1. Добавить например обратные величины от численных,  например 1/days, и создать на их освное другие переменные.
2. Протестировать вклад от устранения выбросов в данных. 
3. Попробовать oversampling/undersampling.
4. Другие модели, отличные от LogisticRegression
5. Более аккуратно переписать ноутбук для публикации, возможно с добавление классов. Текущий документ\проект готов предоставить текущее решение, но оно не является окончательным и скоринг наверняка можно еще улучшить используя пункты 1-4.
 
 
 
## Ответ на задание:

1. Kaggle notebook [Andrey Pravdivtsev] Scoring Model, Kaggle никнейм Andrey Pravdivtsev
https://www.kaggle.com/andreypravdivtsev/andrey-pravdivtsev-scoring-model

2. Kaggle LeaderBoard от 20210203, 9 место Andrey Pravdivtsev скоринг 0.73850

3. https://github.com/AndreyPravdivtsev/SkillFactory-DataScience/tree/master/module_5

4. Какой частью своей работы вы остались особенно довольны?
- Оптимизация гиперпараметров.

5. Что не получилось сделать так, как хотелось? Над чем ещё стоит поработать?
- Только 2 типа (кроме стандартного) разбиение данных тестировалось.
- Другие методы классификации данных не были применены.

6. Что является вашим главным результатом при прохождении этого проекта?
- Подробное решение прикладной категориальной задачи методами ML.
